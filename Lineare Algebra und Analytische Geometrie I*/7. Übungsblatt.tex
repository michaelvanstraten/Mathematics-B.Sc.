\documentclass{../problemset}

\Lecture{Lineare Algebra und Analytische Geometrie I}
\Problemset{7}
\DoOn{3. Dezember 2023}
\author{Michael van Straten}

\begin{document}
\maketitle

\begin{problem}[Unterräume von Vektorräumen]
Sei $K$ ein Körper, $V$ ein $K$-Vektorraum, und seien $U_1$, $U_2$ Unterräume von $V$. Zeigen Sie, dass $U_1 \cup U_2$ genau dann ein Unterraum von $V$ ist, wenn $U_1 \subseteq U_2$ oder $U_2 \subseteq U_1$ gilt.
\begin{proof}
	$ $

	$\Rightarrow$ Annahme: $U_1 \cup U_2$ ist ein Unterraum von $V$.

	Betrachten wir zwei beliebige Elemente $u_1 \in U_1$ und $u_2 \in U_2$.
	Da $U_1 \cup U_2$ ein Vektorraum ist, folgt $u_1 + u_2 \in U_1 \cup U_2$.
	Somit muss entweder $u_1 + u_2 \in U_1$ oder $u_1 + u_2 \in U_2$ gelten.
	Durch Umformung erhalten wir entweder $(u_1 + u_2) - u_1 \in U_1$ oder $(u_1 + u_2) - u_2 \in U_2$.
	Das führt zu $u_2 \in U_1$ oder $u_1 \in U_2$.

	Da $u_1$ und $u_2$ beliebig gewählt wurden, folgt entweder $U_1 \subseteq U_2$ oder $U_2 \subseteq U_1$. \checkmark

	$\Leftarrow$ Annahme: $U_1 \subseteq U_2$ oder $U_2 \subseteq U_1$.

	Wenn $U_1 \subseteq U_2$, dann ist $U_1 \cup U_2 = U_2$.
	Da $U_2$ ein Vektorraum ist, folgt, dass $U_1 \cup U_2$ ein Unterraum von $V$ ist.

	Ebenso, wenn $U_2 \subseteq U_1$, dann ist $U_2 \cup U_1 = U_1$, und auch in diesem Fall ist $U_1 \cup U_2$ ein Unterraum von $V$.  \checkmark

	Somit ist $U_1 \cup U_2$ genau dann ein Unterraum von $V$, wenn $U_1 \subseteq U_2$ oder $U_2 \subseteq U_1$ gilt.
\end{proof}
\end{problem}

\begin{problem}[Lineare Unabhängigkeit in Vektorräumen]
Sei $K$ ein Körper, $V$ ein $K$-Vektorraum. Zeigen oder widerlegen Sie:
\begin{enumerate}
    \item Falls $v_1, \ldots, v_n \in V$ linear unabhängig sind und $\alpha_2, \ldots, \alpha_n \in K$, dann sind die Vektoren $v_1, v_2 + \alpha_2v_1, \ldots, v_n + \alpha_nv_1$ linear unabhängig.
    \item Falls $v_1, v_2, v_3 \in V$ linear unabhängig sind und $1 + 1 \neq 0$ in $K$, dann sind auch die folgenden Vektoren linear unabhängig: $v_{12} := v_1 + v_2$, $v_{23} := v_2 + v_3$, $v_{13} := v_1 + v_3$.
    \item Falls $v_1, v_2, v_3 \in V$ linear unabhängig sind und $1 + 1 = 0$ in $K$, dann sind auch die folgenden Vektoren linear unabhängig: $v_{12} := v_1 + v_2$, $v_{23} := v_2 + v_3$, $v_{13} := v_1 + v_3$.
    \item Für einen Unterkörper $K'$ von $K$ und linear unabhängige Vektoren $v_1, \ldots, v_n$ im $K'$-Vektorraum $V$, sind $v_1, \ldots, v_n$ auch linear unabhängig im $K$-Vektorraum $V$.
\end{enumerate}
\end{problem}

\begin{problem}[Lineare Abhängigkeit bei Funktionen]
Sei $V = \text{Abb}(\mathbb{R}^2, \mathbb{R})$ der $\mathbb{R}$-Vektorraum aller Abbildungen von $\mathbb{R}^2$ nach $\mathbb{R}$, und seien $f_1, f_2, f_3, f_4 \in \text{Abb}(\mathbb{R}^2, \mathbb{R})$ definiert durch
\[ f_1(x, y) := \max(x, y), \quad f_2(x, y) := \min(x, y), \quad f_3(x, y) := x, \quad f_4(x, y) := y. \]
Bestimmen Sie eine Basis von $U = \text{Span}\{f_1, f_2, f_3, f_4\} \subset V$.
\begin{proof}
	$ $

    Betrachten wir $B = \{f_1, f_2, f_3, f_4\}$ als eine mögliche Basis von $U$, da $U = \operatorname{Span} B$ muss lediglich gezeigt oder widerlegen werden das $B$ linear unabhängig ist um zu zeigen da $B$ eine oder keine Base von $U$ ist.

    Wenn $B$ linear unabhängig ist, muss gelten das aus $\alpha_1 f_1 + \alpha_2 f_2 + \alpha_3 f_3 + \alpha_4 f_4 = 0$ folgt $\alpha_1 = \alpha_2 = \alpha_3 = \alpha_4 = $

    Um zu zeigen, dass eine Funktion die Null Funktion ist muss sie an jeder stelle $f(x) = 0$ sein.
    Somit nehmen wir uns 4 Werte, und errechnen, ob folgt das $\alpha_{1 \le n \le 4} = 0$.

    Für $x = 0, y = 1$:
    \begin{align*}
        \alpha_1 \cdot \max(0, 1) + \alpha_2 \cdot \min(0, 1) + \alpha_3 \cdot 0 + \alpha_4 \cdot 1 & = 0         \\
        \Rightarrow \alpha_1 + \alpha_4                                                             & = 0         \\
        \Rightarrow \alpha_1                                                                        & = -\alpha_4
    \end{align*}

    Für $x = 1, y = 0$:
    \begin{align*}
        \alpha_1 \cdot \max(1, 0) + \alpha_2 \cdot \min(1, 0) + \alpha_3 \cdot 1 + \alpha_4 \cdot 0 & = 0         \\
        \Rightarrow \alpha_1 + \alpha_3                                                             & = 0         \\
        \Rightarrow \alpha_1                                                                        & = -\alpha_3 \\
        \Rightarrow \alpha_4                                                                        & = \alpha_3
    \end{align*}

    Für $x = 1, y = 1$:
    \begin{align*}
        \alpha_1 \cdot \max(1, 1) + \alpha_2 \cdot \min(1, 1) + \alpha_3 \cdot 1 + \alpha_4 \cdot 1 & = 0 \\
        \Rightarrow \alpha_1 + \alpha_2 + \alpha_3 + \alpha_4                                       & = 0 \\
        \Rightarrow \alpha_1 + \alpha_2 + 2 \alpha_3                                                & = 0
    \end{align*}

    Für $x = 1, y = 2$:
    \begin{align*}
        \alpha_1 \cdot \max(1, 2) + \alpha_2 \cdot \min(1, 2) + \alpha_3 \cdot 1 + \alpha_4 \cdot 2 & = 0 \\
        \Rightarrow 2\alpha_1 + \alpha_2 + \alpha_3 + 2\alpha_4                                     & = 0 \\
        \Rightarrow 2\alpha_1 + \alpha_2 + 3 \alpha_3                                               & = 0 \\
        \Rightarrow -\alpha_2 - \alpha_3                                                            & = 0 \\
        \Rightarrow \alpha_2 = - \alpha_3
    \end{align*}

    Somit lässt sich der span von $\{f_1, f_2, f_3, f_4\}$ durch $f_1 = f_3 + f_4 - f_2$, sowie $f_2 = f_3 + f_4 - f_2$ sowie $f_3 = f_4 - f_1 - f_2$, sowie $f_4 = f_3 - f_1 - f_2$ darstellen.

    Wähle somit die base $\{f_2, f_3, f_4\}$ und teste, ob linear unabhängig.

    Für $x = 0, y = 1$:
    \begin{align*}
        \alpha_1 \cdot \min(0, 1) + \alpha_2 \cdot 0 + \alpha_3 \cdot 1 & = 0         \\
        \Rightarrow \alpha_1 + \alpha_3                                 & = 0         \\
        \Rightarrow \alpha_1                                            & = -\alpha_3
    \end{align*}

    Für $x = 1, y = 0$:
    \begin{align*}
        \alpha_1 \cdot \min(1, 0) + \alpha_2 \cdot 1 + \alpha_3 \cdot 0 & = 0         \\
        \Rightarrow \alpha_1 + \alpha_2                                 & = 0         \\
        \Rightarrow \alpha_1                                            & = -\alpha_2
    \end{align*}

    Für $x = 1, y = 1$:
    \begin{align*}
        \alpha_1 \cdot \min(1, 1) + \alpha_2 \cdot 1 + \alpha_3 \cdot 1 & = 0 \\
        \Rightarrow \alpha_1 + \alpha_2 + \alpha_3                      & = 0 \\
    \end{align*}

    Da $\alpha_1 = - \alpha_3$ folgt $\alpha_2 = 0$ und da $\alpha_1 = - \alpha_2$ folgt $\alpha_3 = 0$ und somit auch $\alpha_1 = 0$.
    Somit ist $\{f_2, f_3, f_4\}$ linear unabhängig und eine Basis von $U$.

\end{proof}
\end{problem}

\pagebreak

\begin{problem}[Unterräume im $\mathbb{R}^3$]
Geben Sie für jeden der folgenden Unterräume des $\mathbb{R}$-Vektorraums $\mathbb{R}^3$ eine Basis an:
\begin{enumerate}
	\item $U_1 = \{(x_1, x_2, x_3) \in \mathbb{R}^3 \mid x_1 + x_2 + x_3 = 0\}$
	\item $U_2 = \text{Span}\{(2, -3, 1), (1, 1, 3), (-8, 17, 1)\}$
	\item $U_1 \cap U_2$
\end{enumerate}
\begin{proof}
	$ $

	\begin{enumerate}
		\item Beachte, dass die Gleichung $x + y + z = 0$ eine Ebene im $\mathbb{R}^3$ darstellt, die durch die Gleichung
		      \[
			      \alpha_1 \cdot \begin{pmatrix}
				      1 \\
				      0 \\
				      -1
			      \end{pmatrix} + \alpha_2 \cdot \begin{pmatrix}
				      0 \\
				      1 \\
				      -1
			      \end{pmatrix} = \begin{pmatrix}
				      x \\
				      y \\
				      z
			      \end{pmatrix}
		      \]
		      repräsentiert werden kann. Somit lässt sich eine Menge
		      \[
			      B = \left\{\begin{pmatrix}
				      1 \\
				      0 \\
				      -1
			      \end{pmatrix}, \begin{pmatrix}
				      0 \\
				      1 \\
				      -1
			      \end{pmatrix}\right\}
		      \]
		      konstruieren, für die offensichtlich ist, dass sie linear unabhängig ist und teilmenge von $U_1$ ist.

		      Es bleibt zu zeigen, dass $\operatorname{Span} B = U_1$, um zu beweisen, dass $B$ eine Basis von $U_1$ ist.

		      Sei $(x_1, x_2, x_3) \in U_1$ mit $x_1 + x_2 + x_3 = 0 \Leftrightarrow x_3 = - x_1 - x_2$ beliebig, aber fest. Es ist also zu zeigen, dass $\alpha_1, \alpha_2 \in \mathbb{R}$ existieren, sodass
		      \[
			      \alpha_1 \cdot \begin{pmatrix}
				      1 \\
				      0 \\
				      -1
			      \end{pmatrix} + \alpha_2 \cdot \begin{pmatrix}
				      0 \\
				      1 \\
				      -1
			      \end{pmatrix} = \begin{pmatrix}
				      x_1 \\
				      x_2 \\
				      x_3
			      \end{pmatrix}
		      \]

		      Durch einfaches Ausmultiplizieren erhalten wir
		      \begin{align*}
			      x_1 & = \alpha_1                                             \\
			      x_2 & = \alpha_2                                             \\
			      x_3 & = - \alpha_1 - \alpha_2 = - x_1 - x_2 \tag{\checkmark}
		      \end{align*}

		      Somit existieren Werte $\alpha_1, \alpha_2 \in \mathbb{R}$ genau dann, wenn $x_1 + x_2 + x_3 = 0$. Daher ist $B$ eine Basis von $U_1$.
		\item Sei $U_2 = \text{Span}\{(2, -3, 1), (1, 1, 3), (-8, 17, 1)\}$ ein Unterraum des $\mathbb{R}$-Vektorraums $\mathbb{R}^3$.

		      Wir betrachten die Menge $B$:

		      \[
			      B = \left\{
			      \begin{pmatrix}
				      1 \\ 0 \\ 2
			      \end{pmatrix},
			      \begin{pmatrix}
				      0 \\ 1 \\ 1
			      \end{pmatrix}
			      \right\}
		      \]

		      als potenzielle Basis für $U_2$.

		      Um zu zeigen, dass $B$ eine Basis ist, überprüfen wir zwei Bedingungen:

		      1. Die Vektoren in $B$ sind linear unabhängig.

		      2. Der von $B$ erzeugte Raum ist gleich dem Raum $U_2$.

		      Beginnen wir mit der Überprüfung der linearen Unabhängigkeit von $B$:

		      Angenommen, es existieren Skalare $\beta_1$ und $\beta_2$, nicht beide gleich null, sodass

		      \[
			      \beta_1 \begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix} + \beta_2 \begin{pmatrix} 0 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}
		      \]

		      Dies führt zu dem linearen Gleichungssystem:

		      \[
			      \begin{cases}
				      \beta_1 = 0 \\
				      \beta_2 = 0 \\
				      \beta_1 + \beta_2 = 0
			      \end{cases}
		      \]

		      Die Lösung dieses Systems ist $\beta_1 = 0$ und $\beta_2 = 0$, was bedeutet, dass die Vektoren in $B$ linear unabhängig sind.

		      Da die Vektoren in $B$ linear unabhängig sind, überprüfen wir nun, ob der Raum, den sie erzeugen, gleich dem Raum $U_2$ ist.

		      Der Raum, der durch $B$ erzeugt wird, ist der Span der Vektoren $\begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix}$ und $\begin{pmatrix} 0 \\ 1 \\ 1 \end{pmatrix}$. Wir müssen überprüfen, ob jeder Vektor in $U_2$ als Linearkombination dieser beiden Vektoren dargestellt werden kann.

		      Der Vektor $(2, -3, 1)$ kann als $2 \cdot \begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix} + (-5) \cdot \begin{pmatrix} 0 \\ 1 \\ 1 \end{pmatrix}$ dargestellt werden.

		      Der Vektor $(1, 1, 3)$ kann als $1 \cdot \begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix} + 1 \cdot \begin{pmatrix} 0 \\ 1 \\ 1 \end{pmatrix}$ dargestellt werden.

		      Der Vektor $(-8, 17, 1)$ kann als $-8 \cdot \begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix} + 17 \cdot \begin{pmatrix} 0 \\ 1 \\ 1 \end{pmatrix}$ dargestellt werden.

		      Da jeder Vektor in $U_2$ als Linearkombination der Vektoren in $B$ dargestellt werden kann, ist $B$ eine Basis von $U_2$.

		\item Angenommen, die Basen in i) sowie ii) wurden korrekt bestimmt.

		      Unser Ziel ist es, alle Vektoren zu finden, die sowohl in \(U_1\) als auch in \(U_2\) liegen.

		      Dies lässt sich durch die Gleichung

		      \[
			      \alpha_1 \cdot \begin{pmatrix}
				      1 \\
				      0 \\
				      -1
			      \end{pmatrix} + \alpha_2 \cdot \begin{pmatrix}
				      0 \\
				      1 \\
				      -1
			      \end{pmatrix} = \beta_1 \begin{pmatrix}
				      1 \\ 0 \\ 2
			      \end{pmatrix} + \beta_2 \begin{pmatrix}
				      0 \\ 1 \\ 1
			      \end{pmatrix}
		      \]

		      ausdrücken.

		      Um die Beziehung der Koeffizienten \(\alpha_1, \alpha_2, \beta_1\) und \(\beta_2\) zu untersuchen, formen wir um:

		      \[
			      \alpha_1 \cdot \begin{pmatrix}
				      1 \\
				      0 \\
				      -1
			      \end{pmatrix} + \alpha_2 \cdot \begin{pmatrix}
				      0 \\
				      1 \\
				      -1
			      \end{pmatrix} - \beta_1 \begin{pmatrix}
				      1 \\ 0 \\ 2
			      \end{pmatrix} - \beta_2 \begin{pmatrix}
				      0 \\ 1 \\ 1
			      \end{pmatrix} = 0
		      \]

		      Daraus folgt:
		      \[
			      \alpha_1 - \beta_1 = 0 \Rightarrow \alpha_1 = \beta_1
		      \]
		      \[
			      \alpha_2 - \beta_2 = 0 \Rightarrow \alpha_2 = \beta_2
		      \]
		      \[
			      -\alpha_1 - \alpha_2 - 2\beta_1 - \beta_2 = 0
		      \]

		      Was zu
		      \[
			      -3\alpha_1 -3\alpha_2 = 0
		      \]

		      führt. Die Lösung dieser Gleichung ist:
		      \[
			      \alpha_1 = -\alpha_2
		      \]

		      Daher können wir schlussfolgern, dass die Vektoren, die sowohl in \(U_1\) als auch in \(U_2\) liegen, die Form \(\alpha_1 \cdot \begin{pmatrix}
			      1 \\
			      0 \\
			      -1
		      \end{pmatrix} + \alpha_2 \cdot \begin{pmatrix}
			      0 \\
			      1 \\
			      -1
		      \end{pmatrix}\) haben mit der Bedingung, dass \(\alpha_1 - \alpha_2 = 0\).
	\end{enumerate}
\end{proof}
\end{problem}
\end{document}
